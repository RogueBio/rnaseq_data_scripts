## 1. Running FastQC on samples

```
# Directory containing the raw data
raw_data_dir=Data_for_tests/220211_A00181_0425_BHVMJNDSX2

# Find all .fastq files in the raw_data directory and its subdirectories
fastq_files=$(find "$raw_data_dir" -type f \( -iname "*.fastq" -o -iname "*.fastq.gz" -o -iname "*.fq" -o -iname "*.fq.gz" \))

# Define the directory containing the FastQC script (local path, not URL)
fastqc_dir=git_repos/rnaseq_data_scripts

mkdir -p Data_for_tests/fastqc_results
# Define the output directory where FastQC results will be saved
output_dir=Data_for_tests/fastqc_results

# Loop through each .fastq file
for fastq_file in $fastq_files; do
    # Extract file name for unique job naming
    filename=$(basename "$fastq_file" .fastq)
    
    # Submit FastQC job for each file
    sbatch --export=fastq_file="$fastq_file",output_dir="$OUTPUT_DIR" \
           --job-name="fastqc_$filename" \
           "$fastqc_dir/fastqc.sh"
done
```

## Trimming with Trimmomatic
```
# Directory containing the raw data
RAW_DATA_DIR="raw_data path"

# Find all .fastq files in the raw_data directory and its subdirectories
fastq_files=$(find "$RAW_DATA_DIR" -type f -name "*.fastq")

# Define the directory containing the Trimmomatic script (local path, not URL)
trimm_dir="/path/to/your/trimmomatic/script"

# Define the output directory where Trimmomatic results will be saved
OUTPUT_DIR="/path/to/output/directory"

# Loop through each .fastq file
for fastq_file in $fastq_files; do
    # Extract file name for unique job naming
    filename=$(basename "$fastq_file" .fastq)
    
    # Submit Trimmomatic job for each file
    sbatch --export=fastq_file="$fastq_file",output_dir="$OUTPUT_DIR" \
           --job-name="trimm$filename" \
           "$trimm_dir/trimmomatic.sh"
done
```
## FastQC of trimmed reads
```
# Directory containing the trimmed data
TRIM_DATA_DIR="trimmed data path"

# Find all .fastq files in the raw_data directory and its subdirectories
fastq_files=$(find "$TRIM_DATA_DIR" -type f -name "*.fastq")

# Define the directory containing the FastQC script (local path, not URL)
fastqc_dir="/path/to/your/fastqc/script"

# Define the output directory where FastQC results will be saved
OUTPUT_DIR="/path/to/output/directory"

# Loop through each .fastq file
for fastq_file in $fastq_files; do
    # Extract file name for unique job naming
    filename=$(basename "$fastq_file" .fastq)
    
    # Submit FastQC job for each file
    sbatch --export=fastq_file="$fastq_file",output_dir="$OUTPUT_DIR" \
           --job-name="fastqc_$filename" \
           "$fastqc_dir/fastqc.sh"
done
```
## Salmon Alignment
```
##Generating a decoy-aware transcriptome

# Directory containing the reference genome 
ref_genome_dir="/path/to/refgenome/directory"

# Directory containing the reference transcripts data
transcripts_dir="/path/to/refgenome/directory"

#Extract chromosome information from the genome file to make the decoys.txt file
grep "^>" <(gunzip -c ref_genome_dir/GRCm38.primary_assembly.genome.fa.gz) | cut -d " " -f 1 > decoys.txt

#Check
head decoys.txt

#Remove the > symbol from the file
sed -i.bak -e 's/>//g' decoys.txt

#Check
head decoys.txt

#Combine the transcripts and genome file, in this order!
cat transcripts_dir/transcripts.fa.gz ref_genome_dir/refgenome.fa.gz > trans_and_gen.fa.gz
```
#Run salmon index from decoy and transcript/genome file
```
sbatch --export=transcriptome="trans_and_gen.fa.gz",decoy_file="decoys.txt",index_dir="AGAM_PEST_salmon_index" \
       --job-name="salmon_indexing" \
       "$your_script_dir/salmon_decoy_generation.sh"

#Run alignment with Salmon

#Set path to salmon index

salmon_index = "salmon index file/AGAM_PEST_salmon_index" 

#Trimmed fastq file folder

TRIM_DATA_DIR="trimmed data path"

#Loop through directories within the fastq folder (here SRR should be changed to whatever naming system my files will have)

for dir in ${TRIM_DATA_DIR}"/SRR*;do 

#Find R1 and R2 files

r1_file = $(find "$dir" -name"*_1.fastq.gz")
r2_file=$(find "$dir" -name"*_2.fastq.gz")

#Extract sample name

base_filename=$(basename "$dir")

#Run salmon alignment 

echo "Submitting job for sample ${base_filename}"
    
    # Submit sbatch job for Salmon alignment
    sbatch --export=ALL,salmon_index="${salmon_index}",r1_file="${r1_file}",r2_file="${r2_file}",sample_name="${base_filename}",output_dir="${SALMON_OUT_DIR}" \
        salmon_alignment.sh
done
```
## Importing transcript abundance with tximport

library(tximport)
library(DESeq2)

# List of quant.sf files
samples <- c("sample1", "sample2", "sample3")
files <- file.path("path/to/output", paste0(samples, "_quant"), "quant.sf")
names(files) <- samples

tx2gene <- read.csv("path/to/tx2gene.csv")  # Columns: transcript_id, gene_id
txi <- tximport(files, type = "salmon", tx2gene = tx2gene)

sampleTable <- data.frame(condition = c("ctrl", "ctrl", "treated"))
rownames(sampleTable) <- samples

dds <- DESeqDataSetFromTximport(txi, colData = sampleTable, design = ~condition)
dds <- DESeq(dds)

res <- results(dds)

library(GenomicFeatures)
txdb <- makeTxDbFromGFF("your_annotation.gtf")
tx2gene <- select(txdb, keys(txdb, "TXNAME"), "GENEID", "TXNAME")


##On R:

library(tximport)
library(ensembldb)
library(AnnotationHub)
library(DeSeq2)




